{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutable Red Convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos las rutas de los directorios de las imágenes que vamos a utilizar para la red\n",
    "path = \"path\"\n",
    "\n",
    "# Configuramos el tamaño de las imágenes y el batch_size\n",
    "img_size = (225, 225)\n",
    "batch_size = 48\n",
    "\n",
    "# Declaramos las variables donde vamos a guardar los resultados\n",
    "img_names = []\n",
    "img_predictions = []\n",
    "\n",
    "# Creamos los datasets de entrenamiento y validación y los configuramos\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0 / 255.0, validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"sparse\",\n",
    "    color_mode = \"rgb\",\n",
    "    subset = \"training\"\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"sparse\",\n",
    "    color_mode = \"rgb\",\n",
    "    subset = \"validation\"\n",
    ")\n",
    "\n",
    "# Guardamos los nombres de cada clase para luego asignarlos\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "index_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "print(\"Set de entrenamiento: \", len(train_generator))\n",
    "print(\"Set de validacion: \", len(validation_generator))\n",
    "\n",
    "plt.imshow(train_generator[0][0][0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input = tf.keras.layers.Input(shape=(img_size[0], img_size[1], 3))\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation = \"relu\")(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation = \"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation = \"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation = \"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(512, (3, 3), activation = \"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    output = tf.keras.layers.Dense(len(class_indices), activation='softmax')(x)\n",
    "\n",
    "    return tf.keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los Pesos al Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"weight_path\"\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prueba_path = \"img_prueba_path\"\n",
    "\n",
    "for image in os.listdir(img_prueba_path):\n",
    "    img = cv2.imread(os.path.join(img_prueba_path, image), cv2.IMREAD_COLOR)\n",
    "    resized_img = cv2.resize(img, (225, 225), interpolation=cv2.INTER_AREA)\n",
    "    imgRGB = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "    imgRGB_batch = np.expand_dims(imgRGB, axis=0)\n",
    "    prediction = model.predict(imgRGB_batch)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_class_name = index_to_class[predicted_class]\n",
    "    \n",
    "    print(predicted_class_name)\n",
    "    \n",
    "    plt.plot()\n",
    "    plt.imshow(imgRGB)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconocimiento a tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocesar el frame para el modelo\n",
    "    resized_frame = cv2.resize(frame, (225, 225), interpolation=cv2.INTER_AREA)\n",
    "    frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_rgb_batch = np.expand_dims(frame_rgb, axis=0)\n",
    "\n",
    "    # Realizar predicción\n",
    "    prediction = model.predict(frame_rgb_batch)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_class_name = index_to_class[predicted_class]\n",
    "\n",
    "    # Mostrar la predicción en el frame\n",
    "    cv2.putText(frame, f\"Predicción: {predicted_class_name}\", \n",
    "                (10, 50),  # Coordenadas del texto\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,  # Fuente\n",
    "                1,  # Escala de la fuente\n",
    "                (0, 255, 0),  # Color (verde en este caso)\n",
    "                2,  # Grosor de la línea\n",
    "                cv2.LINE_AA)  # Tipo de línea\n",
    "\n",
    "    # Mostrar el frame con texto\n",
    "    cv2.imshow('Objeto', frame)\n",
    "\n",
    "    # Salir si se presiona la tecla ESC\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EntornoSICompleto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
